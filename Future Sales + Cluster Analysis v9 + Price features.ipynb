{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "# Use 3 decimal places in output display\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "CATEGORY_FREQ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get valid shop id\n",
    "def valid_shop_id(id):\n",
    "    if id == 0:\n",
    "        return 57\n",
    "    if id == 1:\n",
    "        return 58\n",
    "#    if id == 23:\n",
    "#        return 24\n",
    "    if id == 11:\n",
    "        return 10\n",
    "    if id == 40:\n",
    "        return 39 \n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214200.00000</td>\n",
       "      <td>214200.00000</td>\n",
       "      <td>214200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>107099.50000</td>\n",
       "      <td>31.64286</td>\n",
       "      <td>11019.39863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61834.35817</td>\n",
       "      <td>17.56193</td>\n",
       "      <td>6252.64459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>30.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53549.75000</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>5381.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>107099.50000</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>11203.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>160649.25000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>16071.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>214199.00000</td>\n",
       "      <td>59.00000</td>\n",
       "      <td>22167.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID      shop_id      item_id\n",
       "count 214200.00000 214200.00000 214200.00000\n",
       "mean  107099.50000     31.64286  11019.39863\n",
       "std    61834.35817     17.56193   6252.64459\n",
       "min        0.00000      2.00000     30.00000\n",
       "25%    53549.75000     16.00000   5381.50000\n",
       "50%   107099.50000     34.50000  11203.00000\n",
       "75%   160649.25000     47.00000  16071.50000\n",
       "max   214199.00000     59.00000  22167.00000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2935849.00000</td>\n",
       "      <td>2935849.00000</td>\n",
       "      <td>2935849.00000</td>\n",
       "      <td>2935849.00000</td>\n",
       "      <td>2935849.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.56991</td>\n",
       "      <td>33.00173</td>\n",
       "      <td>10197.22706</td>\n",
       "      <td>890.85323</td>\n",
       "      <td>1.24264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.42299</td>\n",
       "      <td>16.22697</td>\n",
       "      <td>6324.29735</td>\n",
       "      <td>1729.79963</td>\n",
       "      <td>2.61883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-22.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.00000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>4476.00000</td>\n",
       "      <td>249.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.00000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>9343.00000</td>\n",
       "      <td>399.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.00000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>15684.00000</td>\n",
       "      <td>999.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.00000</td>\n",
       "      <td>59.00000</td>\n",
       "      <td>22169.00000</td>\n",
       "      <td>307980.00000</td>\n",
       "      <td>2169.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_block_num       shop_id       item_id    item_price  item_cnt_day\n",
       "count   2935849.00000 2935849.00000 2935849.00000 2935849.00000 2935849.00000\n",
       "mean         14.56991      33.00173   10197.22706     890.85323       1.24264\n",
       "std           9.42299      16.22697    6324.29735    1729.79963       2.61883\n",
       "min           0.00000       0.00000       0.00000      -1.00000     -22.00000\n",
       "25%           7.00000      22.00000    4476.00000     249.00000       1.00000\n",
       "50%          14.00000      31.00000    9343.00000     399.00000       1.00000\n",
       "75%          23.00000      47.00000   15684.00000     999.00000       1.00000\n",
       "max          33.00000      59.00000   22169.00000  307980.00000    2169.00000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales = pd.read_csv(\"sales_train.csv\")\n",
    "df_sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.59 s, sys: 278 ms, total: 5.86 s\n",
      "Wall time: 5.97 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>item_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2499.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>499.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>317</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>299.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>438</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>299.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>471</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>399.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_cnt_day  item_price\n",
       "0               0        2       27       1.00000  2499.00000\n",
       "1               0        2       33       1.00000   499.00000\n",
       "2               0        2      317       1.00000   299.00000\n",
       "3               0        2      438       1.00000   299.00000\n",
       "4               0        2      471       2.00000   399.00000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_sales['shop_id'] = df_sales['shop_id'].apply(lambda x: valid_shop_id(x))\n",
    "df_sales = df_sales.loc[df_sales['item_cnt_day']>0]\n",
    "df_sales = df_sales.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': 'sum', 'item_price': 'mean'}).reset_index()\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clip\n",
    "df_sales['item_cnt_day'] = np.clip(df_sales['item_cnt_day'], 0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['month'] = df_sales['date_block_num']%12 + 1\n",
    "df_test['month'] = 11\n",
    "df_test['date_block_num'] = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>item_price</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1607369</th>\n",
       "      <td>33</td>\n",
       "      <td>59</td>\n",
       "      <td>22087</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>119.00000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607370</th>\n",
       "      <td>33</td>\n",
       "      <td>59</td>\n",
       "      <td>22088</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>119.00000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607371</th>\n",
       "      <td>33</td>\n",
       "      <td>59</td>\n",
       "      <td>22091</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>179.00000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607372</th>\n",
       "      <td>33</td>\n",
       "      <td>59</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>629.00000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607373</th>\n",
       "      <td>33</td>\n",
       "      <td>59</td>\n",
       "      <td>22102</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date_block_num  shop_id  item_id  item_cnt_day  item_price  month\n",
       "1607369              33       59    22087       6.00000   119.00000     10\n",
       "1607370              33       59    22088       2.00000   119.00000     10\n",
       "1607371              33       59    22091       1.00000   179.00000     10\n",
       "1607372              33       59    22100       1.00000   629.00000     10\n",
       "1607373              33       59    22102       1.00000  1250.00000     10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>item_price</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1607374.00000</td>\n",
       "      <td>1607374.00000</td>\n",
       "      <td>1607374.00000</td>\n",
       "      <td>1607374.00000</td>\n",
       "      <td>1607374.00000</td>\n",
       "      <td>1607374.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.66230</td>\n",
       "      <td>33.09043</td>\n",
       "      <td>10681.30604</td>\n",
       "      <td>2.02878</td>\n",
       "      <td>789.98726</td>\n",
       "      <td>6.15428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.54389</td>\n",
       "      <td>16.46960</td>\n",
       "      <td>6238.68984</td>\n",
       "      <td>2.58019</td>\n",
       "      <td>1549.52683</td>\n",
       "      <td>3.45495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.09000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>5046.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>199.00000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.00000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>10497.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>399.00000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.00000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>16060.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>890.00000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.00000</td>\n",
       "      <td>59.00000</td>\n",
       "      <td>22169.00000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>307980.00000</td>\n",
       "      <td>12.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_block_num       shop_id       item_id  item_cnt_day    item_price  \\\n",
       "count   1607374.00000 1607374.00000 1607374.00000 1607374.00000 1607374.00000   \n",
       "mean         14.66230      33.09043   10681.30604       2.02878     789.98726   \n",
       "std           9.54389      16.46960    6238.68984       2.58019    1549.52683   \n",
       "min           0.00000       2.00000       0.00000       1.00000       0.09000   \n",
       "25%           6.00000      21.00000    5046.00000       1.00000     199.00000   \n",
       "50%          14.00000      31.00000   10497.00000       1.00000     399.00000   \n",
       "75%          23.00000      48.00000   16060.00000       2.00000     890.00000   \n",
       "max          33.00000      59.00000   22169.00000      20.00000  307980.00000   \n",
       "\n",
       "              month  \n",
       "count 1607374.00000  \n",
       "mean        6.15428  \n",
       "std         3.45495  \n",
       "min         1.00000  \n",
       "25%         3.00000  \n",
       "50%         6.00000  \n",
       "75%         9.00000  \n",
       "max        12.00000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1607374 entries, 0 to 1607373\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   date_block_num  1607374 non-null  int64  \n",
      " 1   shop_id         1607374 non-null  int64  \n",
      " 2   item_id         1607374 non-null  int64  \n",
      " 3   item_cnt_day    1607374 non-null  float64\n",
      " 4   item_price      1607374 non-null  float64\n",
      " 5   month           1607374 non-null  int64  \n",
      "dtypes: float64(2), int64(4)\n",
      "memory usage: 73.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>month</th>\n",
       "      <th>date_block_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  shop_id  item_id  month  date_block_num\n",
       "0   0        5     5037     11              34\n",
       "1   1        5     5320     11              34\n",
       "2   2        5     5233     11              34\n",
       "3   3        5     5232     11              34\n",
       "4   4        5     5268     11              34"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_sales.pivot_table(index=['shop_id','item_id'], columns=['date_block_num'], values='item_cnt_day', fill_value=np.nan).reset_index()\n",
    "#df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[(df['shop_id']==2)&(df['item_id']==27), ''.join(('item_prev', str(1)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/andrei/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/andrei/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import r2_score\n",
    "import datetime as dt\n",
    "import holidays\n",
    "from itertools import product\n",
    "import re\n",
    "\n",
    "\n",
    "MAX_ITEM_FEATURES = 25\n",
    "date_ix = 0\n",
    "start_date = dt.datetime.strptime(\"2013-01-01\", \"%Y-%m-%d\")\n",
    "end_date = dt.datetime.strptime(\"2015-11-30\", \"%Y-%m-%d\")\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attributes_names):\n",
    "        self.attributes_names = attributes_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attributes_names].values # convert to NumPy array\n",
    "\n",
    "class CycleTransformator( BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self,  cycle_columns ):\n",
    "        self._cycle_columns = cycle_columns\n",
    "        self._cycle_stats = {}\n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        for column in self._cycle_columns:\n",
    "            self._cycle_stats[column] = { 'max': X[column].max(), 'min': X[column].min() }\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        for column in self._cycle_columns:\n",
    "            self._df[column+'_sin'] = np.sin(2*np.pi/(self._cycle_stats[column]['max']+1)*X[column].fillna(self._cycle_stats[column]['min']-1))\n",
    "            self._df[column+'_cos'] = np.cos(2*np.pi/(self._cycle_stats[column]['max']+1)*X[column].fillna(self._cycle_stats[column]['min']-1))\n",
    "\n",
    "        #self._df = self._df.reset_index(drop=True)\n",
    "        #print('Cycle transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values\n",
    "\n",
    "class ItemTransformator( BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self, max_features ):\n",
    "        self._df_items = pd.read_csv(\"items.csv\")\n",
    "        self._snowball = SnowballStemmer(language=\"russian\")\n",
    "        self._russian_stop_words = stopwords.words(\"russian\")\n",
    "        self._vectorizer = TfidfVectorizer(tokenizer=lambda x: self.__tokenize_sentence(x), max_features=max_features)\n",
    "    \n",
    "    def __tokenize_sentence(self, sentence: str):\n",
    "        self._tokens = word_tokenize(sentence, language=\"russian\")\n",
    "        self._tokens = [i for i in self._tokens if i not in string.punctuation]\n",
    "        self._tokens = [i for i in self._tokens if i not in self._russian_stop_words]\n",
    "        self._tokens = [self._snowball.stem(i) for i in self._tokens]\n",
    "        return self._tokens\n",
    "\n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        self._vectorizer.fit(self._df_items['item_name'])\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "#        self._df_names = pd.DataFrame(index=X.index)\n",
    "        self._df_names = X.merge(self._df_items, how='left', on='item_id')\n",
    "        self._features = self._vectorizer.transform(self._df_names['item_name'])\n",
    "        #self._df = self._df.reset_index(drop=True)\n",
    "        #print('Cycle transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._features\n",
    "\n",
    "\n",
    "class DateTransformator( BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self,  start_date, end_date ):\n",
    "        self._ru_holidays = holidays.Russia()\n",
    "        self._calendar = pd.Series([start_date + dt.timedelta(days=x) for x in range(0, (end_date - start_date + dt.timedelta(days=1)).days)]).rename(\"date\").to_frame()\n",
    "        self._date_dict= {}\n",
    "\n",
    "    def __get_holydays(self, block_num):\n",
    "        return self._date_dict['holyday'][block_num]\n",
    "\n",
    "    def __get_weekends(self, block_num):\n",
    "        return self._date_dict['weekend'][block_num]    \n",
    "\n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        self._calendar[\"bank_holiday\"] = self._calendar[\"date\"].apply(lambda x: self._ru_holidays.get(x))\n",
    "        self._calendar[\"weekday\"] = self._calendar[\"date\"].apply(lambda x: dt.date.isoweekday(x))\n",
    "        self._calendar['weekend'] = self._calendar['weekday'].apply(lambda x: 1 if x in (6,7) else 0)\n",
    "        self._calendar['holyday'] = self._calendar['bank_holiday'].apply(lambda x: 1 if x is not None else 0)\n",
    "        self._calendar['date_block_num'] = self._calendar['date'].apply(lambda x: (x.year-2013)*12+x.month-1)\n",
    "        self._date_dict = self._calendar[['date_block_num','weekend','holyday']].groupby('date_block_num').sum().to_dict()\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        self._df['holydays'] = X['date_block_num'].apply(lambda x: self.__get_holydays(x))\n",
    "        self._df['weekends'] = X['date_block_num'].apply(lambda x: self.__get_weekends(x))\n",
    "        #print('Date transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values\n",
    "\n",
    "class ValueTransformator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._sales = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        index_cols = ['date_block_num', 'shop_id', 'item_id']\n",
    "        shops = X['shop_id'].unique()\n",
    "        items = X['item_id'].unique()\n",
    "        date_blocks = X['date_block_num'].unique()\n",
    "        grid = np.array(list(product(*[date_blocks,shops,items])))\n",
    "        #print(grid)\n",
    "        date_block_max = X['date_block_num'].max() + 1\n",
    "        self._sales = pd.DataFrame(grid, columns = index_cols,dtype=np.int32)\n",
    "        self._sales.to_csv('sales_grid.csv')   \n",
    "        self._sales = self._sales.merge(X, on=index_cols, how='left').fillna(np.nan).reset_index()\n",
    "        self._sales = self._sales.pivot_table(index=['shop_id','item_id'], columns=['date_block_num'], values='item_cnt_day', fill_value=np.nan).reset_index()\n",
    "        self._sales['item_prev0'] = np.nan\n",
    "        self._sales['item_mean3_0'] = np.nan\n",
    "        self._sales['item_mean6_0'] = np.nan\n",
    "        for col in range(1, date_block_max):\n",
    "            self._sales[''.join(('item_prev', str(col)))] = self._sales[col-1]\n",
    "            self._sales[''.join(('item_prev_diff', str(col)))] = self._sales[''.join(('item_prev', str(col)))] - self._sales[''.join(('item_prev', str(col-1)))]\n",
    "            self._sales[''.join(('item_mean3_', str(col)))] = np.nan\n",
    "\n",
    "            if col > 2:\n",
    "                self._sales[''.join(('item_mean3_', str(col)))] = np.nanmean([self._sales[col-1], self._sales[col-2], self._sales[col-3]])\n",
    "        \n",
    "            self._sales[''.join(('item_mean6_', str(col)))] = np.nan\n",
    "            if col > 5:\n",
    "                self._sales[''.join(('item_mean6_', str(col)))] = np.nanmean([self._sales[col-1], self._sales[col-2], self._sales[col-3], self._sales[col-4], self._sales[col-5], self._sales[col-6]])\n",
    "        self._sales.to_csv('sales_fitted.csv')   \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X[['item_prev', 'item_mean3', 'item_mean6']] = np.nan\n",
    "        for index, row in X.iterrows():\n",
    "            block, shop, item = row['date_block_num'].astype(int), row['shop_id'].astype(int), row['item_id'].astype(int)\n",
    "#            print('Index: ',index, ', block: ', block, ', shop: ', shop, ', item: ', item)\n",
    "#            item_prev = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_prev', str(block)))]\n",
    "#            item_mean3 = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_mean3_', str(block)))]\n",
    "#            item_mean6 = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_mean6_', str(block)))]\n",
    "#            print('item_prev: ', item_prev, ', item_mean3: ', item_mean3, ', item_mean6: ', item_mean6)\n",
    "#            X.iloc[index]['item_prev'] = item_prev\n",
    "#            X.iloc[index]['item_mean3'] = item_mean3\n",
    "#            X.iloc[index]['item_mean6'] = item_mean6\n",
    "            if block > 0:\n",
    "                X.at[index, 'item_prev'] = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), block-1]\n",
    "                X.at[index, 'item_mean3'] = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_mean3_', str(block-1)))]\n",
    "                X.at[index, 'item_mean6'] =self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_mean6_', str(block-1)))]\n",
    "        return X[['item_prev', 'item_mean3', 'item_mean6']].values # convert to NumPy array\n",
    "\n",
    "class PriceTransformator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._sales = None\n",
    "    def fit(self, X, y=None):\n",
    "        index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "        shops = X['shop_id'].unique()\n",
    "        items = X['item_id'].unique()\n",
    "        date_blocks = X['date_block_num'].unique()\n",
    "        grid = np.array(list(product(*[date_blocks,shops,items])))\n",
    "        date_block_max = X['date_block_num'].max() + 1\n",
    "        self._sales = pd.DataFrame(grid, columns = index_cols,dtype=np.int32)\n",
    "        self._sales = self._sales.merge(X, on=index_cols, how='left').fillna(np.nan).reset_index()\n",
    "        self._sales = self._sales.pivot_table(index=['shop_id','item_id'], columns=['date_block_num'], values='item_price', fill_value=np.nan).reset_index()\n",
    "        self._sales['price_prev0'] = np.nan\n",
    "        self._sales['price_mean3_0'] = np.nan\n",
    "        self._sales['price_mean6_0'] = np.nan\n",
    "        for col in range(1, date_block_max):\n",
    "            self._sales[''.join(('price_prev', str(col)))] = self._sales[col-1]\n",
    "            self._sales[''.join(('price_prev_diff', str(col)))] = self._sales[''.join(('price_prev', str(col)))] - self._sales[''.join(('price_prev', str(col-1)))]\n",
    "            self._sales[''.join(('price_mean3_', str(col)))] = np.nan\n",
    "\n",
    "            if col > 2:\n",
    "                self._sales[''.join(('price_mean3_', str(col)))] = np.nanmean([self._sales[col-1], self._sales[col-2], self._sales[col-3]])\n",
    "        \n",
    "            self._sales[''.join(('price_mean6_', str(col)))] = np.nan\n",
    "            if col > 5:\n",
    "                self._sales[''.join(('price_mean6_', str(col)))] = np.nanmean([self._sales[col-1], self._sales[col-2], self._sales[col-3], self._sales[col-4], self._sales[col-5], self._sales[col-6]])\n",
    "           \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X[['price_prev', 'price_mean3', 'price_mean6']] = np.nan\n",
    "        for index, row in X.iterrows():\n",
    "            block, shop, item = row['date_block_num'].astype(int), row['shop_id'].astype(int), row['item_id'].astype(int)\n",
    "            if block > 0:\n",
    "                X.at[index, 'price_prev'] = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), block-1]\n",
    "                X.at[index, 'price_mean3'] = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('price_mean3_', str(block-1)))]\n",
    "                X.at[index, 'price_mean6'] = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('price_mean6_', str(block-1)))]\n",
    "        return X[['price_prev', 'price_mean3', 'price_mean6']].values # convert to NumPy array\n",
    "    \n",
    "class ShopTransformator( BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        df_shops = pd.read_csv(\"shops.csv\", index_col='shop_id')\n",
    "        df_shops.drop([0,1], inplace=True)\n",
    "        df_shops['city'] = df_shops['shop_name'].apply(lambda x: self.__shop_city(x))\n",
    "        df_shops['type'] = df_shops['shop_name'].apply(lambda x: self.__shop_type(x))\n",
    "        self.__shops = df_shops[['city', 'type']].to_dict()\n",
    "        \n",
    "    \n",
    "    def __shop_type(self, shop):\n",
    "        #types = ['ТК', 'ТЦ', 'ТРК', 'ТРЦ']\n",
    "        p = re.compile(r\"(Т[РКЦ]+)\")\n",
    "        r = p.search(shop)\n",
    "        if r is not None: return r.group(1) \n",
    "        if 'нлайн' in shop: return 'Онлайн'\n",
    "        if 'нтернет' in shop: return 'Онлайн'\n",
    "        return 'Магазин'\n",
    "\n",
    "    # get city\n",
    "    def __shop_city(self, shop):\n",
    "        p = re.compile(r\"^([а-яА-Я\\.]*)\")\n",
    "        r = p.search(shop)\n",
    "        if r is not None: return r.group(1) \n",
    "        return 'Unknown'\n",
    "\n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        self._df['city'] = X['shop_id'].apply(lambda x: self.__shops['city'][x])\n",
    "        self._df['type'] = X['shop_id'].apply(lambda x: self.__shops['type'][x])\n",
    "        #print('Date transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values\n",
    "\n",
    "class CategoriesTransformator( BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        df_items = pd.read_csv(\"items.csv\", index_col='item_id')\n",
    "        df_categories = pd.read_csv(\"item_categories.csv\")\n",
    "        df_categories = df_items.merge(df_categories, how='left', on='item_category_id')\n",
    "        df_categories['category'] = df_categories['item_category_name'].str.split('[-(]', n=0).str[0].str.strip()\n",
    "        df_categories['digital'] = df_categories['item_category_name'].str.contains('цифра', case=False).astype(int)\n",
    "        self.__categories = df_categories[['category', 'digital']].to_dict()\n",
    "        \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        self._df['category'] = X['item_id'].apply(lambda x: self.__categories['category'][x])\n",
    "        self._df['digital'] = X['item_id'].apply(lambda x: self.__categories['digital'][x])\n",
    "        #print('Date transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "def regression_results(y_true, y_pred):\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmse(actual, predict):\n",
    "    predict = np.array(predict)\n",
    "    actual = np.array(actual)\n",
    "    distance = predict - actual\n",
    "    square_distance = distance ** 2\n",
    "    mean_square_distance = square_distance.mean()\n",
    "    score = np.sqrt(mean_square_distance)\n",
    "    return score\n",
    "\n",
    "rmse_score = make_scorer(rmse, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_attribs = ['item_cnt_prev_month','item_cnt_prev_diff','prev_itemQ','item_cnt_prev_year']\n",
    "#num_attribs = ['prev_month','prev_diff', 'prev_itemQ', 'mean3', 'mean6', 'weekends', 'holydays', 'prev_item_price', 'prev_shop_price', 'prev_item_month', 'prev_shop_month']\n",
    "#num_attribs = ['prev_month', 'prev_itemQ', 'mean3', 'mean6', 'weekends', 'holydays', 'prev_item_price', 'prev_shop_price', 'prev_item_month', 'prev_shop_month']\n",
    "#l12_cols = item_labels.columns.values\n",
    "#num_attribs = np.concatenate([num_attribs,l12_cols])\n",
    "#num_attribs = ['digital']\n",
    "#cat_attribs = ['shop_cluster', 'category_cluster']\n",
    "#cat_attribs = ['city_cluster','shop_cluster', 'category_cluster']\n",
    "#cat_attribs = ['city_cluster','shop_cluster', 'category_cluster', 'shop_type', 'subcategory', 'category', 'city', 'shop_mega', 'digital']\n",
    "#cat_attribs = ['shop_type', 'category', 'city', 'shop_mega', 'digital']\n",
    "#cat_attribs = ['shop_type', 'category', 'city']\n",
    "#cat_attribs = ['city_cluster','shop_cluster', 'category_cluster', 'city', 'shop_type', 'category']\n",
    "#cat_attribs = ['shop_cluster', 'category']\n",
    "#num_attribs = ['item_id','shop_id','digital']\n",
    "#cat_attribs = ['category']\n",
    "date_attribs = ['month']\n",
    "\n",
    "#num_pipeline = Pipeline([\n",
    "#    ('selector', DataFrameSelector(num_attribs)),\n",
    "##    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "#    ('std_scaler', StandardScaler()),\n",
    "#])\n",
    "#cat_pipeline = Pipeline([\n",
    "#    ('selector', DataFrameSelector(cat_attribs)),\n",
    "#    ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "#])\n",
    "shop_pipeline = Pipeline([\n",
    "    ('shop_transformator', ShopTransformator()),\n",
    "    ('shop_encoder', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "categories_pipeline = Pipeline([\n",
    "    ('cat_transformator', CategoriesTransformator()),\n",
    "    ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "item_pipeline = Pipeline([\n",
    "    ('item_transformator', ItemTransformator(max_features=MAX_ITEM_FEATURES)),\n",
    "])\n",
    "date_pipeline = Pipeline([\n",
    "    ('date_transformator', DateTransformator(start_date=start_date, end_date=end_date)),\n",
    "    ('date_scaler', StandardScaler()),\n",
    "])\n",
    "value_pipeline = Pipeline([\n",
    "    ('value_transformator', ValueTransformator()),\n",
    "    ('value_scaler', StandardScaler()),\n",
    "])\n",
    "price_pipeline = Pipeline([\n",
    "    ('price_transformator', PriceTransformator()),\n",
    "    ('price_scaler', StandardScaler()),\n",
    "])\n",
    "counted_pipeline = Pipeline([\n",
    "    ('cycle_transformator', CycleTransformator(cycle_columns=date_attribs)),\n",
    "])\n",
    "\n",
    "#all_features_pipeline = FeatureUnion(transformer_list=[\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "#    ('shop_pipeline',      shop_pipeline),\n",
    "#    ('catgories_pipeline', categories_pipeline),\n",
    "#    ('item_pipeline',      item_pipeline),\n",
    "#    ('date_pipeline',      date_pipeline),\n",
    "    ('value_pipeline',     value_pipeline),\n",
    "    ('price_pipeline',     price_pipeline),\n",
    "#    ('counted_pipeline',   counted_pipeline),\n",
    "])\n",
    "\n",
    "#full_pipeline = FeatureUnion(transformer_list=[\n",
    "#    ('all_features_pipeline', all_features_pipeline),\n",
    "#    ('std_scaler', StandardScaler()),\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#df_sells_in_month = df_sells_in_month.dropna()\n",
    "\n",
    "#X_train_data = df_sells_in_month[df_sells_in_month['date_block_num'] < 24].copy()\n",
    "#X_test_data = df_sells_in_month[df_sells_in_month['date_block_num'] > 23].copy()\n",
    "#X_train = X_train_data[['item_cnt_prev_month','revenue_prev', 'item_cnt_prev_diff','revenue_prev', 'prev_itemQ', 'prev_revenueQ', 'shop_type', 'shop_mega', 'shop_cluster', 'city', 'city_cluster', 'category', 'subcategory', 'digital', 'category_cluster', 'month']]\n",
    "#X_test = X_test_data[['item_cnt_prev_month','revenue_prev', 'prev_itemQ', 'prev_revenueQ', 'shop_type', 'shop_mega', 'shop_cluster', 'city', 'city_cluster', 'category', 'subcategory', 'digital', 'category_cluster', 'month']]\n",
    "\n",
    "#X_train = X_train_data[['item_cnt_prev_month','revenue_prev', 'prev_itemQ', 'prev_revenueQ', 'shop_cluster', 'city_cluster', 'category_cluster', 'month']]\n",
    "#X_test = X_test_data[['item_cnt_prev_month','revenue_prev', 'prev_itemQ', 'prev_revenueQ', 'shop_cluster', 'city_cluster', 'category_cluster', 'month']]\n",
    "\n",
    "X_all = df_sales\n",
    "X_train = df_sales[df_sales['date_block_num'] < 24]\n",
    "X_test = df_sales[df_sales['date_block_num'] > 23]\n",
    "\n",
    "\n",
    "Y_train = X_train['item_cnt_day'].copy()\n",
    "Y_test = X_test['item_cnt_day'].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "full_pipeline.fit(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_prepared = full_pipeline.transform(X_train)\n",
    "X_train_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test_prepared = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_pred_prepared = full_pipeline.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#poly = PolynomialFeatures(degree=2)\n",
    "#X_train_prepared = poly.fit_transform(X_train_prepared)\n",
    "#X_test_prepared = poly.transform(X_test_prepared)\n",
    "#X_train_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Std Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# train\n",
    "tree_reg = DecisionTreeRegressor(random_state=57)\n",
    "tree_reg.fit(X_train_prepared, Y_train)\n",
    "\n",
    "# predict\n",
    "predictions = tree_reg.predict(X_train_prepared)\n",
    "\n",
    "#scores = cross_val_score(tree_reg, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\")\n",
    "#print('%s: %f (%f)' % ('Tree: ', scores.mean(), scores.std()))\n",
    "#tree_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(tree_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = tree_reg.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))\n",
    "#regression_results(Y_pred , Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# train\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "predictions = lin_reg.predict(X_train_prepared)\n",
    "\n",
    "#scores = cross_val_score(lin_reg, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\")\n",
    "#print('%s: %f (%f)' % ('LinReg: ', scores.mean(), scores.std()))\n",
    "#lin_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(lin_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = lin_reg.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))\n",
    "#regression_results(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=57, n_jobs=3, verbose=1)\n",
    "print('Fitting...')\n",
    "forest_reg.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "print('Predicting...')\n",
    "predictions = forest_reg.predict(X_train_prepared)\n",
    "\n",
    "#print('Cross validating...')\n",
    "#scores = cross_val_score(forest_reg, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\", n_jobs=4, verbose=1)\n",
    "#print('%s: %f (%f)' % ('Forest: ', scores.mean(), scores.std()))\n",
    "#forest_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(forest_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = forest_reg.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = forest_reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"]\n",
    "#cat_one_hot_attribs = list(cat_encoder.categories_[0]) + list(cat_encoder.categories_[1]) + list(cat_encoder.categories_[2])\n",
    "counted_encoder = counted_pipeline.named_steps[\"cycle_transformator\"]\n",
    "counted_attribs = list(counted_encoder._df.columns)\n",
    "#attributes = num_attribs + cat_one_hot_attribs + counted_attribs\n",
    "#attributes = np.concatenate([num_attribs, l12_cols, cat_one_hot_attribs, counted_attribs])\n",
    "attributes = np.concatenate([num_attribs, l12_cols, counted_attribs])\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alpha = 0.1\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "lasso.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "predictions = lasso.predict(X_train_prepared)\n",
    "\n",
    "scores = cross_val_score(lasso, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\")\n",
    "print('%s: %f (%f)' % ('Lasso: ', scores.mean(), scores.std()))\n",
    "#lin_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(lin_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = lasso.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "enet = ElasticNet(alpha=alpha, l1_ratio=0.8)\n",
    "enet.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "predictions = enet.predict(X_train_prepared)\n",
    "\n",
    "scores = cross_val_score(enet, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\")\n",
    "print('%s: %f (%f)' % ('Enet: ', scores.mean(), scores.std()))\n",
    "#lin_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(lin_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = enet.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "boost_reg = XGBRegressor(random_state=57, verbosity=1)\n",
    "print('Fitting...')\n",
    "boost_reg.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "print('Predicting...')\n",
    "predictions = boost_reg.predict(X_train_prepared)\n",
    "\n",
    "#print('Cross validating...')\n",
    "#scores = cross_val_score(forest_reg, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\", n_jobs=4, verbose=1)\n",
    "#print('%s: %f (%f)' % ('Forest: ', scores.mean(), scores.std()))\n",
    "#forest_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(forest_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = boost_reg.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# train\n",
    "neighbor_reg = KNeighborsRegressor(n_jobs=3)\n",
    "print('Fitting...')\n",
    "neighbor_reg.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "print('Predicting...')\n",
    "predictions = neighbor_reg.predict(X_train_prepared)\n",
    "\n",
    "#print('Cross validating...')\n",
    "#scores = cross_val_score(neighbor_reg, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\", n_jobs=4, verbose=1)\n",
    "#print('%s: %f (%f)' % ('NeighborReg: ', scores.mean(), scores.std()))\n",
    "#lin_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(lin_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = neighbor_reg.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test['34_scaled'] = (20*(df_test[34] - np.min(df_test[34]))/np.ptp(df_test[34]))   \n",
    "#df_test['34'] = np.clip(df_test[34], 0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_prepared = full_pipeline.transform(X_pred)\n",
    "#Y_pred = enet.predict(X_pred_prepared)\n",
    "Y_pred = boost_reg.predict(X_pred_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sells_in_month_34['item_cnt_month'] = 0\n",
    "df_sells_in_month_34.loc[df_sells_in_month_34['prev_month'] > 0, 'item_cnt_month'] = np.clip(Y_pred, 0, 20)\n",
    "df_sells_in_month_34['item_cnt_month'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_test, df_sells_in_month_34, on=['shop_id','item_id'], how='left')\n",
    "df_test = df_test.fillna(0)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['ID', 'item_cnt_month']].to_csv('submission111_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_submission = pd.read_csv('sample_submission.csv')\n",
    "#df_submission['item_cnt_month'] = df_test['34_scaled']\n",
    "#df_submission['item_cnt_month'] = np.clip(df_prediction['item_cnt_month'], 0, 20)\n",
    "#df_submission['item_cnt_month'] = np.clip(Y_pred, 0, 20)\n",
    "#df_submission.to_csv('submission107_1.csv', index=False)\n",
    "#df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission107_2.csv\n",
    "a few seconds ago by Andrey Vest\n",
    "\n",
    "RandomForest, merge test after prediction, previous , -cluster features + item features, clip only targets\n",
    "1.14185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
