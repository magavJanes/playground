{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "# Use 3 decimal places in output display\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "CATEGORY_FREQ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get valid shop id\n",
    "def valid_shop_id(id):\n",
    "    if id == 0:\n",
    "        return 57\n",
    "    if id == 1:\n",
    "        return 58\n",
    "#    if id == 23:\n",
    "#        return 24\n",
    "    if id == 11:\n",
    "        return 10\n",
    "    if id == 40:\n",
    "        return 39 \n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv(\"sales_train.csv\")\n",
    "df_sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_sales['shop_id'] = df_sales['shop_id'].apply(lambda x: valid_shop_id(x))\n",
    "df_sales = df_sales.loc[df_sales['item_cnt_day']>0]\n",
    "df_sales = df_sales.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': 'sum', 'item_price': 'mean'}).reset_index()\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clip\n",
    "df_sales['item_cnt_day'] = np.clip(df_sales['item_cnt_day'], 0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['month'] = df_sales['date_block_num']%12 + 1\n",
    "df_test['month'] = 11\n",
    "df_test['date_block_num'] = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_sales.pivot_table(index=['shop_id','item_id'], columns=['date_block_num'], values='item_cnt_day', fill_value=np.nan).reset_index()\n",
    "#df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[(df['shop_id']==2)&(df['item_id']==27), ''.join(('item_prev', str(1)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import r2_score\n",
    "import datetime as dt\n",
    "import holidays\n",
    "from itertools import product\n",
    "import re\n",
    "\n",
    "\n",
    "MAX_ITEM_FEATURES = 25\n",
    "date_ix = 0\n",
    "start_date = dt.datetime.strptime(\"2013-01-01\", \"%Y-%m-%d\")\n",
    "end_date = dt.datetime.strptime(\"2015-11-30\", \"%Y-%m-%d\")\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attributes_names):\n",
    "        self.attributes_names = attributes_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attributes_names].values # convert to NumPy array\n",
    "\n",
    "class CycleTransformator( BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self,  cycle_columns ):\n",
    "        self._cycle_columns = cycle_columns\n",
    "        self._cycle_stats = {}\n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        for column in self._cycle_columns:\n",
    "            self._cycle_stats[column] = { 'max': X[column].max(), 'min': X[column].min() }\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        for column in self._cycle_columns:\n",
    "            self._df[column+'_sin'] = np.sin(2*np.pi/(self._cycle_stats[column]['max']+1)*X[column].fillna(self._cycle_stats[column]['min']-1))\n",
    "            self._df[column+'_cos'] = np.cos(2*np.pi/(self._cycle_stats[column]['max']+1)*X[column].fillna(self._cycle_stats[column]['min']-1))\n",
    "\n",
    "        #self._df = self._df.reset_index(drop=True)\n",
    "        #print('Cycle transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values\n",
    "\n",
    "class ItemTransformator( BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self, max_features ):\n",
    "        self._df_items = pd.read_csv(\"items.csv\")\n",
    "        self._snowball = SnowballStemmer(language=\"russian\")\n",
    "        self._russian_stop_words = stopwords.words(\"russian\")\n",
    "        self._vectorizer = TfidfVectorizer(tokenizer=lambda x: self.__tokenize_sentence(x), max_features=max_features)\n",
    "    \n",
    "    def __tokenize_sentence(self, sentence: str):\n",
    "        self._tokens = word_tokenize(sentence, language=\"russian\")\n",
    "        self._tokens = [i for i in self._tokens if i not in string.punctuation]\n",
    "        self._tokens = [i for i in self._tokens if i not in self._russian_stop_words]\n",
    "        self._tokens = [self._snowball.stem(i) for i in self._tokens]\n",
    "        return self._tokens\n",
    "\n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        self._vectorizer.fit(self._df_items['item_name'])\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "#        self._df_names = pd.DataFrame(index=X.index)\n",
    "        self._df_names = X.merge(self._df_items, how='left', on='item_id')\n",
    "        self._features = self._vectorizer.transform(self._df_names['item_name'])\n",
    "        #self._df = self._df.reset_index(drop=True)\n",
    "        #print('Cycle transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._features\n",
    "\n",
    "\n",
    "class DateTransformator( BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self,  start_date, end_date ):\n",
    "        self._ru_holidays = holidays.Russia()\n",
    "        self._calendar = pd.Series([start_date + dt.timedelta(days=x) for x in range(0, (end_date - start_date + dt.timedelta(days=1)).days)]).rename(\"date\").to_frame()\n",
    "        self._date_dict= {}\n",
    "\n",
    "    def __get_holydays(self, block_num):\n",
    "        return self._date_dict['holyday'][block_num]\n",
    "\n",
    "    def __get_weekends(self, block_num):\n",
    "        return self._date_dict['weekend'][block_num]    \n",
    "\n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        self._calendar[\"bank_holiday\"] = self._calendar[\"date\"].apply(lambda x: self._ru_holidays.get(x))\n",
    "        self._calendar[\"weekday\"] = self._calendar[\"date\"].apply(lambda x: dt.date.isoweekday(x))\n",
    "        self._calendar['weekend'] = self._calendar['weekday'].apply(lambda x: 1 if x in (6,7) else 0)\n",
    "        self._calendar['holyday'] = self._calendar['bank_holiday'].apply(lambda x: 1 if x is not None else 0)\n",
    "        self._calendar['date_block_num'] = self._calendar['date'].apply(lambda x: (x.year-2013)*12+x.month-1)\n",
    "        self._date_dict = self._calendar[['date_block_num','weekend','holyday']].groupby('date_block_num').sum().to_dict()\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        self._df['holydays'] = X['date_block_num'].apply(lambda x: self.__get_holydays(x))\n",
    "        self._df['weekends'] = X['date_block_num'].apply(lambda x: self.__get_weekends(x))\n",
    "        #print('Date transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values\n",
    "\n",
    "class ValueTransformator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._sales = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        index_cols = ['date_block_num', 'shop_id', 'item_id']\n",
    "        shops = X['shop_id'].unique()\n",
    "        items = X['item_id'].unique()\n",
    "        date_blocks = X['date_block_num'].unique()\n",
    "        grid = np.array(list(product(*[date_blocks,shops,items])))\n",
    "        #print(grid)\n",
    "        date_block_max = X['date_block_num'].max() + 1\n",
    "        self._sales = pd.DataFrame(grid, columns = index_cols,dtype=np.int32)\n",
    "        self._sales.to_csv('sales_grid.csv')   \n",
    "        self._sales = self._sales.merge(X, on=index_cols, how='left').fillna(np.nan).reset_index()\n",
    "        self._sales = self._sales.pivot_table(index=['shop_id','item_id'], columns=['date_block_num'], values='item_cnt_day', fill_value=np.nan).reset_index()\n",
    "        self._sales['item_prev0'] = np.nan\n",
    "        self._sales['item_mean3_0'] = np.nan\n",
    "        self._sales['item_mean6_0'] = np.nan\n",
    "        for col in range(1, date_block_max):\n",
    "            self._sales[''.join(('item_prev', str(col)))] = self._sales[col-1]\n",
    "            self._sales[''.join(('item_prev_diff', str(col)))] = self._sales[''.join(('item_prev', str(col)))] - self._sales[''.join(('item_prev', str(col-1)))]\n",
    "            self._sales[''.join(('item_mean3_', str(col)))] = np.nan\n",
    "\n",
    "            if col > 2:\n",
    "                self._sales[''.join(('item_mean3_', str(col)))] = np.nanmean([self._sales[col-1], self._sales[col-2], self._sales[col-3]])\n",
    "        \n",
    "            self._sales[''.join(('item_mean6_', str(col)))] = np.nan\n",
    "            if col > 5:\n",
    "                self._sales[''.join(('item_mean6_', str(col)))] = np.nanmean([self._sales[col-1], self._sales[col-2], self._sales[col-3], self._sales[col-4], self._sales[col-5], self._sales[col-6]])\n",
    "        self._sales.to_csv('sales_fitted.csv')   \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X[['item_prev', 'item_mean3', 'item_mean6']] = np.nan\n",
    "        for index, row in X.iterrows():\n",
    "            block, shop, item = row['date_block_num'].astype(int), row['shop_id'].astype(int), row['item_id'].astype(int)\n",
    "#            print('Index: ',index, ', block: ', block, ', shop: ', shop, ', item: ', item)\n",
    "#            item_prev = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_prev', str(block)))]\n",
    "#            item_mean3 = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_mean3_', str(block)))]\n",
    "#            item_mean6 = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_mean6_', str(block)))]\n",
    "#            print('item_prev: ', item_prev, ', item_mean3: ', item_mean3, ', item_mean6: ', item_mean6)\n",
    "#            X.iloc[index]['item_prev'] = item_prev\n",
    "#            X.iloc[index]['item_mean3'] = item_mean3\n",
    "#            X.iloc[index]['item_mean6'] = item_mean6\n",
    "            X.at[index, 'item_prev'] = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_prev', str(block)))]\n",
    "            X.at[index, 'item_mean3'] = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_mean3_', str(block)))]\n",
    "            X.at[index, 'item_mean6'] =self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('item_mean6_', str(block)))]\n",
    "        return X[['item_prev', 'item_mean3', 'item_mean6']].values # convert to NumPy array\n",
    "\n",
    "class PriceTransformator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._sales = None\n",
    "    def fit(self, X, y=None):\n",
    "        index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "        shops = X['shop_id'].unique()\n",
    "        items = X['item_id'].unique()\n",
    "        date_blocks = X['date_block_num'].unique()\n",
    "        grid = np.array(list(product(*[date_blocks,shops,items])))\n",
    "        date_block_max = X['date_block_num'].max() + 1\n",
    "        self._sales = pd.DataFrame(grid, columns = index_cols,dtype=np.int32)\n",
    "        self._sales = self._sales.merge(X, on=index_cols, how='left').fillna(np.nan).reset_index()\n",
    "        self._sales = self._sales.pivot_table(index=['shop_id','item_id'], columns=['date_block_num'], values='item_price', fill_value=np.nan).reset_index()\n",
    "        self._sales['price_prev0'] = np.nan\n",
    "        self._sales['price_mean3_0'] = np.nan\n",
    "        self._sales['price_mean6_0'] = np.nan\n",
    "        for col in range(1, date_block_max):\n",
    "            self._sales[''.join(('price_prev', str(col)))] = self._sales[col-1]\n",
    "            self._sales[''.join(('price_prev_diff', str(col)))] = self._sales[''.join(('price_prev', str(col)))] - self._sales[''.join(('price_prev', str(col-1)))]\n",
    "            self._sales[''.join(('price_mean3_', str(col)))] = np.nan\n",
    "\n",
    "            if col > 2:\n",
    "                self._sales[''.join(('price_mean3_', str(col)))] = np.nanmean([self._sales[col-1], self._sales[col-2], self._sales[col-3]])\n",
    "        \n",
    "            self._sales[''.join(('price_mean6_', str(col)))] = np.nan\n",
    "            if col > 5:\n",
    "                self._sales[''.join(('price_mean6_', str(col)))] = np.nanmean([self._sales[col-1], self._sales[col-2], self._sales[col-3], self._sales[col-4], self._sales[col-5], self._sales[col-6]])\n",
    "           \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X[['price_prev', 'price_mean3', 'price_mean6']] = np.nan\n",
    "        for index, row in X.iterrows():\n",
    "            block, shop, item = row['date_block_num'].astype(int), row['shop_id'].astype(int), row['item_id'].astype(int)\n",
    "            X.iloc[index]['price_prev'] = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('price_prev', str(block)))]\n",
    "            X.iloc[index]['price_mean3'] = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('price_mean3_', str(block)))]\n",
    "            X.iloc[index]['price_mean6'] = self._sales.loc[(self._sales['shop_id']==shop)&(self._sales['item_id']==item), ''.join(('price_mean6_', str(block)))]\n",
    "        return X[['price_prev', 'price_mean3', 'price_mean6']].values # convert to NumPy array\n",
    "    \n",
    "class ShopTransformator( BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        df_shops = pd.read_csv(\"shops.csv\", index_col='shop_id')\n",
    "        df_shops.drop([0,1], inplace=True)\n",
    "        df_shops['city'] = df_shops['shop_name'].apply(lambda x: self.__shop_city(x))\n",
    "        df_shops['type'] = df_shops['shop_name'].apply(lambda x: self.__shop_type(x))\n",
    "        self.__shops = df_shops[['city', 'type']].to_dict()\n",
    "        \n",
    "    \n",
    "    def __shop_type(self, shop):\n",
    "        #types = ['ТК', 'ТЦ', 'ТРК', 'ТРЦ']\n",
    "        p = re.compile(r\"(Т[РКЦ]+)\")\n",
    "        r = p.search(shop)\n",
    "        if r is not None: return r.group(1) \n",
    "        if 'нлайн' in shop: return 'Онлайн'\n",
    "        if 'нтернет' in shop: return 'Онлайн'\n",
    "        return 'Магазин'\n",
    "\n",
    "    # get city\n",
    "    def __shop_city(self, shop):\n",
    "        p = re.compile(r\"^([а-яА-Я\\.]*)\")\n",
    "        r = p.search(shop)\n",
    "        if r is not None: return r.group(1) \n",
    "        return 'Unknown'\n",
    "\n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        self._df['city'] = X['shop_id'].apply(lambda x: self.__shops['city'][x])\n",
    "        self._df['type'] = X['shop_id'].apply(lambda x: self.__shops['type'][x])\n",
    "        #print('Date transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values\n",
    "\n",
    "class CategoriesTransformator( BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        df_items = pd.read_csv(\"items.csv\", index_col='item_id')\n",
    "        df_categories = pd.read_csv(\"item_categories.csv\")\n",
    "        df_categories = df_items.merge(df_categories, how='left', on='item_category_id')\n",
    "        df_categories['category'] = df_categories['item_category_name'].str.split('[-(]', n=0).str[0].str.strip()\n",
    "        df_categories['digital'] = df_categories['item_category_name'].str.contains('цифра', case=False).astype(int)\n",
    "        self.__categories = df_categories[['category', 'digital']].to_dict()\n",
    "        \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        self._df['category'] = X['item_id'].apply(lambda x: self.__categories['category'][x])\n",
    "        self._df['digital'] = X['item_id'].apply(lambda x: self.__categories['digital'][x])\n",
    "        #print('Date transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "def regression_results(y_true, y_pred):\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmse(actual, predict):\n",
    "    predict = np.array(predict)\n",
    "    actual = np.array(actual)\n",
    "    distance = predict - actual\n",
    "    square_distance = distance ** 2\n",
    "    mean_square_distance = square_distance.mean()\n",
    "    score = np.sqrt(mean_square_distance)\n",
    "    return score\n",
    "\n",
    "rmse_score = make_scorer(rmse, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_attribs = ['item_cnt_prev_month','item_cnt_prev_diff','prev_itemQ','item_cnt_prev_year']\n",
    "#num_attribs = ['prev_month','prev_diff', 'prev_itemQ', 'mean3', 'mean6', 'weekends', 'holydays', 'prev_item_price', 'prev_shop_price', 'prev_item_month', 'prev_shop_month']\n",
    "#num_attribs = ['prev_month', 'prev_itemQ', 'mean3', 'mean6', 'weekends', 'holydays', 'prev_item_price', 'prev_shop_price', 'prev_item_month', 'prev_shop_month']\n",
    "#l12_cols = item_labels.columns.values\n",
    "#num_attribs = np.concatenate([num_attribs,l12_cols])\n",
    "#num_attribs = ['digital']\n",
    "#cat_attribs = ['shop_cluster', 'category_cluster']\n",
    "#cat_attribs = ['city_cluster','shop_cluster', 'category_cluster']\n",
    "#cat_attribs = ['city_cluster','shop_cluster', 'category_cluster', 'shop_type', 'subcategory', 'category', 'city', 'shop_mega', 'digital']\n",
    "#cat_attribs = ['shop_type', 'category', 'city', 'shop_mega', 'digital']\n",
    "#cat_attribs = ['shop_type', 'category', 'city']\n",
    "#cat_attribs = ['city_cluster','shop_cluster', 'category_cluster', 'city', 'shop_type', 'category']\n",
    "#cat_attribs = ['shop_cluster', 'category']\n",
    "#num_attribs = ['item_id','shop_id','digital']\n",
    "#cat_attribs = ['category']\n",
    "date_attribs = ['month']\n",
    "\n",
    "#num_pipeline = Pipeline([\n",
    "#    ('selector', DataFrameSelector(num_attribs)),\n",
    "##    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "#    ('std_scaler', StandardScaler()),\n",
    "#])\n",
    "#cat_pipeline = Pipeline([\n",
    "#    ('selector', DataFrameSelector(cat_attribs)),\n",
    "#    ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "#])\n",
    "shop_pipeline = Pipeline([\n",
    "    ('shop_transformator', ShopTransformator()),\n",
    "    ('shop_encoder', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "categories_pipeline = Pipeline([\n",
    "    ('cat_transformator', CategoriesTransformator()),\n",
    "    ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "item_pipeline = Pipeline([\n",
    "    ('item_transformator', ItemTransformator(max_features=MAX_ITEM_FEATURES)),\n",
    "])\n",
    "date_pipeline = Pipeline([\n",
    "    ('date_transformator', DateTransformator(start_date=start_date, end_date=end_date)),\n",
    "    ('date_scaler', StandardScaler()),\n",
    "])\n",
    "value_pipeline = Pipeline([\n",
    "    ('value_transformator', ValueTransformator()),\n",
    "    ('value_scaler', StandardScaler()),\n",
    "])\n",
    "price_pipeline = Pipeline([\n",
    "    ('price_transformator', PriceTransformator()),\n",
    "    ('price_scaler', StandardScaler()),\n",
    "])\n",
    "counted_pipeline = Pipeline([\n",
    "    ('cycle_transformator', CycleTransformator(cycle_columns=date_attribs)),\n",
    "])\n",
    "\n",
    "#all_features_pipeline = FeatureUnion(transformer_list=[\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "#    ('shop_pipeline',      shop_pipeline),\n",
    "#    ('catgories_pipeline', categories_pipeline),\n",
    "#    ('item_pipeline',      item_pipeline),\n",
    "#    ('date_pipeline',      date_pipeline),\n",
    "    ('value_pipeline',     value_pipeline),\n",
    "#    ('price_pipeline',     price_pipeline),\n",
    "#    ('counted_pipeline',   counted_pipeline),\n",
    "])\n",
    "\n",
    "#full_pipeline = FeatureUnion(transformer_list=[\n",
    "#    ('all_features_pipeline', all_features_pipeline),\n",
    "#    ('std_scaler', StandardScaler()),\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#df_sells_in_month = df_sells_in_month.dropna()\n",
    "\n",
    "#X_train_data = df_sells_in_month[df_sells_in_month['date_block_num'] < 24].copy()\n",
    "#X_test_data = df_sells_in_month[df_sells_in_month['date_block_num'] > 23].copy()\n",
    "#X_train = X_train_data[['item_cnt_prev_month','revenue_prev', 'item_cnt_prev_diff','revenue_prev', 'prev_itemQ', 'prev_revenueQ', 'shop_type', 'shop_mega', 'shop_cluster', 'city', 'city_cluster', 'category', 'subcategory', 'digital', 'category_cluster', 'month']]\n",
    "#X_test = X_test_data[['item_cnt_prev_month','revenue_prev', 'prev_itemQ', 'prev_revenueQ', 'shop_type', 'shop_mega', 'shop_cluster', 'city', 'city_cluster', 'category', 'subcategory', 'digital', 'category_cluster', 'month']]\n",
    "\n",
    "#X_train = X_train_data[['item_cnt_prev_month','revenue_prev', 'prev_itemQ', 'prev_revenueQ', 'shop_cluster', 'city_cluster', 'category_cluster', 'month']]\n",
    "#X_test = X_test_data[['item_cnt_prev_month','revenue_prev', 'prev_itemQ', 'prev_revenueQ', 'shop_cluster', 'city_cluster', 'category_cluster', 'month']]\n",
    "\n",
    "X_all = df_sales\n",
    "X_train = df_sales[df_sales['date_block_num'] < 24]\n",
    "X_test = df_sales[df_sales['date_block_num'] > 23]\n",
    "\n",
    "\n",
    "Y_train = X_train['item_cnt_day'].copy()\n",
    "Y_test = X_test['item_cnt_day'].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit(X_all)\n",
    "X_train_prepared = full_pipeline.transform(X_train)\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "X_pred_prepared = full_pipeline.transform(df_test)\n",
    "X_train_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#poly = PolynomialFeatures(degree=2)\n",
    "#X_train_prepared = poly.fit_transform(X_train_prepared)\n",
    "#X_test_prepared = poly.transform(X_test_prepared)\n",
    "#X_train_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Std Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# train\n",
    "tree_reg = DecisionTreeRegressor(random_state=57)\n",
    "tree_reg.fit(X_train_prepared, Y_train)\n",
    "\n",
    "# predict\n",
    "predictions = tree_reg.predict(X_train_prepared)\n",
    "\n",
    "#scores = cross_val_score(tree_reg, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\")\n",
    "#print('%s: %f (%f)' % ('Tree: ', scores.mean(), scores.std()))\n",
    "#tree_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(tree_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = tree_reg.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))\n",
    "#regression_results(Y_pred , Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# train\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "predictions = lin_reg.predict(X_train_prepared)\n",
    "\n",
    "#scores = cross_val_score(lin_reg, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\")\n",
    "#print('%s: %f (%f)' % ('LinReg: ', scores.mean(), scores.std()))\n",
    "#lin_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(lin_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = lin_reg.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))\n",
    "#regression_results(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=57, n_jobs=3, verbose=1)\n",
    "print('Fitting...')\n",
    "forest_reg.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "print('Predicting...')\n",
    "predictions = forest_reg.predict(X_train_prepared)\n",
    "\n",
    "#print('Cross validating...')\n",
    "#scores = cross_val_score(forest_reg, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\", n_jobs=4, verbose=1)\n",
    "#print('%s: %f (%f)' % ('Forest: ', scores.mean(), scores.std()))\n",
    "#forest_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(forest_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = forest_reg.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = forest_reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"]\n",
    "#cat_one_hot_attribs = list(cat_encoder.categories_[0]) + list(cat_encoder.categories_[1]) + list(cat_encoder.categories_[2])\n",
    "counted_encoder = counted_pipeline.named_steps[\"cycle_transformator\"]\n",
    "counted_attribs = list(counted_encoder._df.columns)\n",
    "#attributes = num_attribs + cat_one_hot_attribs + counted_attribs\n",
    "#attributes = np.concatenate([num_attribs, l12_cols, cat_one_hot_attribs, counted_attribs])\n",
    "attributes = np.concatenate([num_attribs, l12_cols, counted_attribs])\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alpha = 0.1\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "lasso.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "predictions = lasso.predict(X_train_prepared)\n",
    "\n",
    "scores = cross_val_score(lasso, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\")\n",
    "print('%s: %f (%f)' % ('Lasso: ', scores.mean(), scores.std()))\n",
    "#lin_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(lin_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = lasso.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "enet = ElasticNet(alpha=alpha, l1_ratio=0.8)\n",
    "enet.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "predictions = enet.predict(X_train_prepared)\n",
    "\n",
    "scores = cross_val_score(enet, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\")\n",
    "print('%s: %f (%f)' % ('Enet: ', scores.mean(), scores.std()))\n",
    "#lin_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(lin_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = enet.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "boost_reg = XGBRegressor(random_state=57, verbosity=1)\n",
    "print('Fitting...')\n",
    "boost_reg.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "print('Predicting...')\n",
    "predictions = boost_reg.predict(X_train_prepared)\n",
    "\n",
    "#print('Cross validating...')\n",
    "#scores = cross_val_score(forest_reg, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\", n_jobs=4, verbose=1)\n",
    "#print('%s: %f (%f)' % ('Forest: ', scores.mean(), scores.std()))\n",
    "#forest_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(forest_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = boost_reg.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# train\n",
    "neighbor_reg = KNeighborsRegressor(n_jobs=3)\n",
    "print('Fitting...')\n",
    "neighbor_reg.fit(X_train_prepared, Y_train)\n",
    "# predict\n",
    "print('Predicting...')\n",
    "predictions = neighbor_reg.predict(X_train_prepared)\n",
    "\n",
    "#print('Cross validating...')\n",
    "#scores = cross_val_score(neighbor_reg, X_train_prepared, Y_train, cv=tscv, scoring=\"r2\", n_jobs=4, verbose=1)\n",
    "#print('%s: %f (%f)' % ('NeighborReg: ', scores.mean(), scores.std()))\n",
    "#lin_rmse_scores = np.sqrt(-scores)\n",
    "#display_scores(lin_rmse_scores)\n",
    "\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_train, predictions) )\n",
    "\n",
    "print('Testing...')\n",
    "Y_pred = neighbor_reg.predict(X_test_prepared)\n",
    "#Y_pred = np.clip(Y_pred, 0, 20)\n",
    "print(\"R2-score: %.2f\" % r2_score(Y_test, Y_pred) )\n",
    "print(\"MSE: %.6f\" % mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test['34_scaled'] = (20*(df_test[34] - np.min(df_test[34]))/np.ptp(df_test[34]))   \n",
    "#df_test['34'] = np.clip(df_test[34], 0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_prepared = full_pipeline.transform(X_pred)\n",
    "#Y_pred = enet.predict(X_pred_prepared)\n",
    "Y_pred = boost_reg.predict(X_pred_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sells_in_month_34['item_cnt_month'] = 0\n",
    "df_sells_in_month_34.loc[df_sells_in_month_34['prev_month'] > 0, 'item_cnt_month'] = np.clip(Y_pred, 0, 20)\n",
    "df_sells_in_month_34['item_cnt_month'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_test, df_sells_in_month_34, on=['shop_id','item_id'], how='left')\n",
    "df_test = df_test.fillna(0)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['ID', 'item_cnt_month']].to_csv('submission111_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_submission = pd.read_csv('sample_submission.csv')\n",
    "#df_submission['item_cnt_month'] = df_test['34_scaled']\n",
    "#df_submission['item_cnt_month'] = np.clip(df_prediction['item_cnt_month'], 0, 20)\n",
    "#df_submission['item_cnt_month'] = np.clip(Y_pred, 0, 20)\n",
    "#df_submission.to_csv('submission107_1.csv', index=False)\n",
    "#df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission107_2.csv\n",
    "a few seconds ago by Andrey Vest\n",
    "\n",
    "RandomForest, merge test after prediction, previous , -cluster features + item features, clip only targets\n",
    "1.14185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
